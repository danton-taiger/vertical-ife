{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "1. Rigth now the detection is sensitive about the rotation of the document to increse the results we'll try to make it non-sensitive at least being able to detect it if it's horizontal or vertical\n",
    "2. The previous implementation were based on the contourn detection, due to the document is almost white it can't detect it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook basic set-up\n",
    "* [Width](#Width)\n",
    "* [Larger](#Larger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full width notebook\n",
    "<a id='Width'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger output cells\n",
    "<a id='Larger'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "* [Libraries import](#Libraries)\n",
    "* [Load images from the notebook location](#Load)\n",
    "* [Helper functions](#Helper)\n",
    "* [New Logic](#New)\n",
    "* [Results](#Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries imports\n",
    "<a id='Libraries'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project we'll be using:\n",
    "1. opencv-python cv2 for image analysis\n",
    "2. numpy for image treatment\n",
    "3. matplotlib for data visualization\n",
    "4. re for python regrex, to filter the ocr result\n",
    "5. pytesseract to use tesseract ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the notebook we'll be using:\n",
    "1. ipywidgets to create a interactive interface\n",
    "2. glob to get the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatSlider, IntSlider\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from the notebook location\n",
    "<a id='Load'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['screenshot_images/1+CAguilarA.png', 'screenshot_images/1+CAraujoA.png', 'screenshot_images/1+CCarrancoA.png', 'screenshot_images/1+CCerdaA.png', 'screenshot_images/1+CCosmeA.png', 'screenshot_images/1+CCreixellA.png', 'screenshot_images/1+CElizondoA.png', 'screenshot_images/1+CEspinosaA.png', 'screenshot_images/1+CGaonaA.png', 'screenshot_images/1+CGarciaA.png', 'screenshot_images/1+CGarduñoA.png', 'screenshot_images/1+CGomezA.png', 'screenshot_images/1+CLafontt.png', 'screenshot_images/1+CMorenoA.png', 'screenshot_images/1+CPelayoA.png', 'screenshot_images/1+CRamosA.png', 'screenshot_images/1+CReyesA.png', 'screenshot_images/1+CRodriguezA.png', 'screenshot_images/1+CSanchezA.png', 'screenshot_images/1+CSebastianA.png', 'screenshot_images/1+CValadezA.png', 'screenshot_images/1+CValenciaA.png']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Datasets:\n",
    "1. screenshot_images/ resized documents\n",
    "2. pdf2image_images/ documents after pdf2image\n",
    "3. pymu_images/ documents after pymu\n",
    "'''\n",
    "datasets = ['pymu_images/','pdf2image_images/','screenshot_images']\n",
    "PATH = \"pymu_images/\"\n",
    "images = (glob.glob(PATH + \"*.png\") + glob.glob(PATH + \"*.jpg\") + glob.glob(PATH + \"*.jpeg\"))\n",
    "images.sort()\n",
    "\n",
    "analyze_front_page = '0'\n",
    "analyze_back_page = '1'\n",
    "\n",
    "#Comment if you want to analyze both\n",
    "images = [image for image in images if analyze_back_page in image]\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {'CRamosA': '0444129470503', 'CSanchezA': '2790085382298', 'CGomezA': '5346130536730',\n",
    "               'CCerdaA': '0222126960915', 'CMorenoA': '0951128596486', 'CCarrancoA': '1816005189775',\n",
    "               'CCreixellA': '2005085456052', 'CGarciaA': '5516097875963', 'CGaonaA': '0571127293101',\n",
    "               'CCosmeA': '1562030398181', 'CRodriguezA': '0762131304665', 'CAraujoA': '4131125952452',\n",
    "               'CReyesA': '5042126099530', 'CLafontt': '0298085448574', 'CGarduñoA': '5440119486648',\n",
    "               'CSebastianA': '0869109802492', 'CPelayoA': '3337123943354', 'CElizondoA': '0758129194328',\n",
    "               'CValenciaA': '1458076631036', 'CValadezA': '1131121264819', 'CAguilarA': '0344131287270',\n",
    "               'CEspinosaA': '4305134739645','CVelazquezA':'0869109802492'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "<a id='Helper'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_area(contour):\n",
    "    \"\"\"\n",
    "    :param contour:\n",
    "    :return the area of the contour:\n",
    "    \"\"\"\n",
    "    _, _, w, h = cv2.boundingRect(contour)\n",
    "    return w * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_contour(contours):\n",
    "    \"\"\"\n",
    "    :param contours:\n",
    "    :return: the contour with the bigger area\n",
    "    \"\"\"\n",
    "\n",
    "    return sorted(contours, reverse=True, key=contour_area)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_contours(img):\n",
    "    \"\"\"\n",
    "    :param img:\n",
    "    :return the number of contours of an image:\n",
    "    \"\"\"\n",
    "    FIRST_THRESHOLD = 140\n",
    "\n",
    "    _, blackest_parts = cv2.threshold(img, FIRST_THRESHOLD, 255, cv2.THRESH_BINARY)\n",
    "    _, contours, _ = cv2.findContours(\n",
    "        blackest_parts, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    return len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contour_center(image, contour, text, color):\n",
    "\n",
    "    M = cv2.moments(contour)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    cv2.circle(image, (cX, cY), 7, color, -1)\n",
    "    cv2.putText(image, text, (cX - 20, cY - 20), cv2.FONT_HERSHEY_SIMPLEX, 4, color, 5)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangular(contour):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param contour: \n",
    "    :return Bool if the contour is rectangular: \n",
    "    \"\"\"\n",
    "\n",
    "    return len(approximate_contour(contour)) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangular_with_proportion(contour, min, max):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param contour: :param minimum: :param maximun: :return     Returns whether the proportion heigth/width or \n",
    "    width/heigth of the contour is between minimum and maximun: \n",
    "    \"\"\"\n",
    "    _, _, width, height = cv2.boundingRect(contour)\n",
    "    # IMPROVE add something to get the corners and check if it's a squared based on this\n",
    "    if rectangular(contour) and (\n",
    "        (min < height / width < max) or (min < width / height < max)\n",
    "    ):\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_contour(contour):\n",
    "    \"\"\"\n",
    "\n",
    "    :param contour:\n",
    "    :return the approximate contour:\n",
    "    \"\"\"\n",
    "\n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.04 * peri, True)\n",
    "\n",
    "    return approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_points(points):\n",
    "    \"\"\"\n",
    "    Returns the end points of the list points\n",
    "    \n",
    "    :param points:\n",
    "    :return  an array [\"down_left\" \"top_left\" \"top_right\" \"down_right\"]:\n",
    "    \"\"\"\n",
    "    sorted_x = sorted(points, key=lambda i: i[0], reverse=True)\n",
    "\n",
    "    # Compares the y coordinate of the two points with biggest x which we'll be the right ones to decide which one is the top_right and which one is the down_right\n",
    "    # If y is bigger down_right\n",
    "    if sorted_x[0][1] > sorted_x[1][1]:\n",
    "        down_right = sorted_x[0]\n",
    "        top_right = sorted_x[1]\n",
    "    else:\n",
    "        down_right = sorted_x[1]\n",
    "        top_right = sorted_x[0]\n",
    "\n",
    "    # Compares the y coordinate of the two points with lowest x which we'll be the left ones to decide which one is the top_left and which one is the down_left\n",
    "    if sorted_x[-1][1] > sorted_x[-2][1]:\n",
    "        down_left = sorted_x[-1]\n",
    "        top_left = sorted_x[-2]\n",
    "    else:\n",
    "        down_left = sorted_x[-2]\n",
    "        top_left = sorted_x[-1]\n",
    "\n",
    "    return [down_left, top_left, top_right, down_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_box_points(contour):\n",
    "    \"\"\"\n",
    "    Return the corners of the rectangle in a dictionary\n",
    "\n",
    "    :param contour:\n",
    "    :return dict(\"down_left\", \"top_left\", \"top_right\", \"down_right\"):\n",
    "    \"\"\"\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = corner_points(box)\n",
    "\n",
    "    box_dict = {\n",
    "        \"down_left\": (int(box[0][0]), int(box[0][1])),\n",
    "        \"top_left\": (int(box[1][0]), int(box[1][1])),\n",
    "        \"top_right\": (int(box[2][0]), int(box[2][1])),\n",
    "        \"down_right\": (int(box[3][0]), int(box[3][1])),\n",
    "    }\n",
    "\n",
    "    return box_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(mat, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image (angle in degrees) and expands image to avoid cropping\n",
    "\n",
    "    :param mat:\n",
    "    :param angle:\n",
    "    :return img:\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = mat.shape[:2]  # image shape has 3 dimensions\n",
    "    image_center = (\n",
    "        width / 2,\n",
    "        height / 2,\n",
    "    )  # getRotationMatrix2D needs coordinates in reverse order (width, height) compared to shape\n",
    "\n",
    "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "\n",
    "    # rotation calculates the cos and sin, taking absolutes of those.\n",
    "    abs_cos = abs(rotation_mat[0, 0])\n",
    "    abs_sin = abs(rotation_mat[0, 1])\n",
    "\n",
    "    # find the new width and height bounds\n",
    "    bound_w = int(height * abs_sin + width * abs_cos)\n",
    "    bound_h = int(height * abs_cos + width * abs_sin)\n",
    "\n",
    "    # subtract old image center (bringing image back to origo) and adding the new image center coordinates\n",
    "    rotation_mat[0, 2] += bound_w / 2 - image_center[0]\n",
    "    rotation_mat[1, 2] += bound_h / 2 - image_center[1]\n",
    "\n",
    "    # rotate image with the new bounds and translated rotation matrix\n",
    "    rotated_mat = cv2.warpAffine(mat, rotation_mat, (bound_w, bound_h))\n",
    "    \n",
    "    return rotated_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New logic\n",
    "<a id='New'></a>\n",
    "\n",
    "0. [Detect document size](#0)\n",
    "1. [Calculate kernel](#5)\n",
    "2. [Detect the barcode](#1)\n",
    "3. [Detect the rotation based on the barcode](#2)\n",
    "4. [Crop the ocr numbers based on the barcode proportion and rotation](#3)\n",
    "5. [Reports](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Detect the document size\n",
    "<a id='0'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_document(img):\n",
    "    \"\"\"\n",
    "    Resize a document if it's bigger than 2236 × 1672\n",
    "    \n",
    "    :param img: \n",
    "    :return img: \n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    height_proportion = height/1672\n",
    "    width_proportion = width/2236\n",
    "    \n",
    "    if  height_proportion > 1 or width_proportion > 1:\n",
    "        if height_proportion > width_proportion:\n",
    "                img = cv2.resize(img, None, fx= 1 / height_proportion, fy= 1 / height_proportion)\n",
    "        else:\n",
    "                img = cv2.resize(img, None, fx= 1 / width_proportion, fy= 1 / width_proportion)\n",
    "                \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculate kernel\n",
    "<a id='5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kernel(img):\n",
    "    \"\"\"\n",
    "    Simple proportion\n",
    "    On the proportion a 2236px width needs a 18px horizontal kernel\n",
    "    On the proportion a 1672px height needs a 14px vertical kernel\n",
    "\n",
    "    :param img:\n",
    "    :return width_kernel, height_kernel:\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    width_kernel = round(width / 2236 * 18)\n",
    "    height_kernel = round(height / 1672 * 14)\n",
    "    \n",
    "    return width_kernel, height_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Detect the barcode\n",
    "<a id='1'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barcode_detection(img, out, show_all):\n",
    "    \"\"\"\n",
    "    Gets the barcode form the IFE documents.\n",
    "    Based on:\n",
    "        1. Is the biggest black area\n",
    "        2. His proportion\n",
    "    \"\"\"\n",
    "    FIRST_THRESHOLD = 150\n",
    "    NUMBER_OF_DILATIONS = 9\n",
    "    \n",
    "    width_kernel, height_kernel = calculate_kernel(img)\n",
    "    \n",
    "    HORIZONTAL_STRUCTURE = cv2.getStructuringElement(cv2.MORPH_RECT, (width_kernel, 1))\n",
    "    VERTICAL_STRUCTURE = cv2.getStructuringElement(cv2.MORPH_RECT, (1, height_kernel))\n",
    "\n",
    "\n",
    "    \n",
    "    #Thresholding black zones \n",
    "    _, blackest_parts = cv2.threshold(img,FIRST_THRESHOLD,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    if show_all:\n",
    "        \n",
    "        plt.figure(figsize = (20,20))\n",
    "        plt.title(\"First threshold\", fontsize=20)\n",
    "        plt.imshow(blackest_parts,cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    #Remove little points\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(blackest_parts, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    \n",
    "    # Dilate the areas to remove the spaces between the bars\n",
    "    #IMPROVE other kernel that works best with lines\n",
    "    #IMPROVE something called blob?\n",
    "    blackest_parts_dilated_horizontal = cv2.dilate(opening,HORIZONTAL_STRUCTURE,NUMBER_OF_DILATIONS)\n",
    "    blackest_parts_dilated = cv2.dilate(blackest_parts_dilated_horizontal,VERTICAL_STRUCTURE,NUMBER_OF_DILATIONS)\n",
    "\n",
    "    if show_all:\n",
    "        \n",
    "        plt.figure(figsize = (20,20))\n",
    "        plt.title(\"Dilate\", fontsize=20)\n",
    "        plt.imshow(blackest_parts_dilated,cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "    kernel = np.ones((width_kernel,height_kernel),np.uint8)\n",
    "    hitormiss = cv2.morphologyEx(blackest_parts_dilated, cv2.MORPH_HITMISS, kernel)\n",
    "    \n",
    "    if show_all:\n",
    "        \n",
    "        plt.figure(figsize = (20,20))\n",
    "        plt.title(\"hit or miss morph\", fontsize=20)\n",
    "        plt.imshow(hitormiss,cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "    # Get the contours\n",
    "    _, contours, _ = cv2.findContours(hitormiss,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    #Gets rectangular contours with a ratio width/height or height/width of 0.15 or 0.25 as the proportion of the barcode is 0.2\n",
    "    filtered_contours = sorted([contour for contour in contours if rectangular_with_proportion(contour, 0.15, 0.25)],reverse = True, key = contour_area)\n",
    "    \n",
    "    if filtered_contours:\n",
    "        \n",
    "        rect = cv2.minAreaRect(filtered_contours[0])\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(out,[box],0,(0,0,255),2)\n",
    "        cv2.drawContours(out, [approximate_contour(filtered_contours[0])], -1, (0, 255, 0), 5)\n",
    "        \n",
    "        if show_all:\n",
    "            \n",
    "            plt.figure(figsize = (20,20))\n",
    "            plt.title(\"bar_code_detected\", fontsize=20)\n",
    "            plt.imshow(out)\n",
    "            plt.show()\n",
    "        \n",
    "        return approximate_contour(filtered_contours[0])\n",
    "    else:\n",
    "        \n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Detect the rotation based on the barcode\n",
    "<a id='2'></a>\n",
    "\n",
    "1. Split the image based on the Up, Down, Left, Right of the code detected until some proportions\n",
    "2. Checks the number of contours in this areas\n",
    "3. Returns the rotation of the document\n",
    "    * If Up then its 180º\n",
    "    * If Down then its 0º\n",
    "    * If Left then its 270º clockwise\n",
    "    * If Right then its 90º clockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barcode_rotation(img, out, barcode_contour, show_all):\n",
    "    \"\"\"\n",
    "    Returns the orientation of the barcode based on the number of contours of the up and down contours in case is \n",
    "    horizontal, and left and right in case is vertical \n",
    "    \n",
    "    :param img: \n",
    "    :param barcode_contour: \n",
    "    :return orientation: \n",
    "    \"\"\"\n",
    "\n",
    "    box_dict = contour_box_points(barcode_contour)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(barcode_contour)\n",
    "\n",
    "    # If it's horizontal\n",
    "    if w / h > 1:\n",
    "\n",
    "        top_crop = img[\n",
    "            int(box_dict[\"top_left\"][1] - 3  * h) : box_dict[\"top_left\"][1],\n",
    "            box_dict[\"top_left\"][0] : box_dict[\"top_right\"][0],\n",
    "        ]\n",
    "        bottom_crop = img[\n",
    "            box_dict[\"down_left\"][1] : int(box_dict[\"down_left\"][1] + 3 * h),\n",
    "            box_dict[\"down_left\"][0] : box_dict[\"down_right\"][0],\n",
    "        ]\n",
    "\n",
    "        if show_all:\n",
    "\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            plt.title(\"top_crop\", fontsize=20)\n",
    "            plt.imshow(top_crop, cmap=\"gray\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            plt.title(\"bottom_crop\", fontsize=20)\n",
    "            plt.imshow(bottom_crop, cmap=\"gray\")\n",
    "            plt.show()\n",
    "\n",
    "        if number_of_contours(top_crop) > number_of_contours(bottom_crop):\n",
    "\n",
    "            return 180\n",
    "\n",
    "        else:\n",
    "\n",
    "            return 0\n",
    "\n",
    "    # If it's vertical\n",
    "    else:\n",
    "\n",
    "        left_crop = img[\n",
    "            box_dict[\"top_left\"][1] : box_dict[\"down_left\"][1],\n",
    "            int(box_dict[\"down_left\"][0] - 3  * w) : box_dict[\"down_left\"][0],\n",
    "        ]\n",
    "        right_crop = img[\n",
    "            box_dict[\"top_right\"][1] : box_dict[\"down_right\"][1],\n",
    "            box_dict[\"down_right\"][0] : int(box_dict[\"down_right\"][0] + 3  * w),\n",
    "        ]\n",
    "\n",
    "        if show_all:\n",
    "\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            plt.title(\"left_crop\", fontsize=20)\n",
    "            plt.imshow(left_crop, cmap=\"gray\")\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(20, 20))\n",
    "            plt.title(\"right_crop\", fontsize=20)\n",
    "            plt.imshow(right_crop, cmap=\"gray\")\n",
    "            plt.show()\n",
    "\n",
    "        if number_of_contours(left_crop) > number_of_contours(right_crop):\n",
    "            return 270\n",
    "        else:\n",
    "\n",
    "            return 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the number ocr\n",
    "<a id='3'></a>\n",
    "\n",
    "Using the proportion of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_numbers(img, out, barcode_contour, flip, show_all):\n",
    "    \"\"\"\n",
    "    Returns an image with the numbers cropped based on the barcode and it's orientation \n",
    "\n",
    "    :param img: \n",
    "    :param barcode_contour: \n",
    "    :param flip: \n",
    "    :return img: \n",
    "    \"\"\"    \n",
    "\n",
    "    box_dict = contour_box_points(barcode_contour)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(barcode_contour)\n",
    "\n",
    "    if flip == 0:\n",
    "        # Use down left point as reference\n",
    "\n",
    "        x_1 = int(box_dict[\"down_left\"][0] - (h * 1.05))\n",
    "        x_2 = int(box_dict[\"down_left\"][0] - (h * 0.65))\n",
    "\n",
    "        y_1 = int(box_dict[\"down_left\"][1] + (h * 0.03))\n",
    "        y_2 = int(box_dict[\"down_left\"][1] + (h * 2.40))\n",
    "\n",
    "        numbers = img[y_1:y_2, x_1:x_2]\n",
    "\n",
    "        numbers_rotated = rotate_image(numbers, 270)\n",
    "\n",
    "    elif flip == 180:\n",
    "        # Use top right point as reference\n",
    "\n",
    "        x_1 = int(box_dict[\"top_right\"][0] + (h * 0.65))\n",
    "        x_2 = int(box_dict[\"top_right\"][0] + (h * 1.05))\n",
    "\n",
    "        y_1 = int(box_dict[\"top_right\"][1] - (h * 2.40))\n",
    "        y_2 = int(box_dict[\"top_right\"][1] - (h * 0.03))\n",
    "\n",
    "        numbers = img[y_1:y_2, x_1:x_2]\n",
    "\n",
    "        numbers_rotated = rotate_image(numbers, 90)\n",
    "\n",
    "    elif flip == 90:\n",
    "        # Use down right point as reference\n",
    "\n",
    "        y_1 = int(box_dict[\"down_right\"][1] + (w * 0.65))\n",
    "        y_2 = int(box_dict[\"down_right\"][1] + (w * 1.05))\n",
    "\n",
    "        x_1 = int(box_dict[\"down_right\"][0] + (w * 0.03))\n",
    "        x_2 = int(box_dict[\"down_right\"][0] + (w * 2.40))\n",
    "\n",
    "        numbers = img[y_1:y_2, x_1:x_2]\n",
    "\n",
    "        numbers_rotated = rotate_image(numbers, 180)\n",
    "\n",
    "    elif flip == 270:\n",
    "        # Use top left point as reference\n",
    "\n",
    "        y_1 = int(box_dict[\"top_left\"][1] - (w * 1.05))\n",
    "        y_2 = int(box_dict[\"top_left\"][1] - (w * 0.65))\n",
    "\n",
    "        x_1 = int(box_dict[\"top_left\"][0] - (w * 2.40))\n",
    "        x_2 = int(box_dict[\"top_left\"][0] - (w * 0.03))\n",
    "\n",
    "        numbers = img[y_1:y_2, x_1:x_2]\n",
    "\n",
    "        numbers_rotated = rotate_image(numbers, 0)\n",
    "\n",
    "    if show_all:\n",
    "\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.title(\"numbers_rotated\", fontsize=20)\n",
    "        plt.imshow(numbers_rotated, cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "    return numbers_rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports\n",
    "<a id='4'></a>\n",
    "\n",
    "Takes the croped image and the original image path, runs the Tesseract Ocr with the OCR-A model and compared it with the real value annotated on the path of the file that follows this format name_rotation_codeNumber\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tesseract(img):\n",
    "    \"\"\"\n",
    "    gi\n",
    "    Performs a tesseract analysis with the OCR model over the img with some filters to improve his quality and \n",
    "    filters the result based on regex and size that has to be 13 \n",
    "    :param img: \n",
    "    :return string ocr code: \n",
    "    \"\"\"\n",
    "    try:\n",
    "        from PIL import Image\n",
    "    except ImportError:\n",
    "        import Image\n",
    "    import pytesseract\n",
    "\n",
    "    # If you don't have tesseract executable in your PATH, include the following:\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"/usr/local/bin/tesseract\"\n",
    "    \n",
    "    '''Z = img.reshape((-1,3))\n",
    "\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "    \n",
    "    # define criteria, number of clusters(K) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 8\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Now convert back into uint8, and make original image\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "    '''\n",
    "    \n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    if width > 200:   \n",
    "        #Remove noise\n",
    "        '''kernel = np.ones((3, 3),np.uint8)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)'''\n",
    "        blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "        _,img = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    else:\n",
    "        # If it's little make a resize\n",
    "        img = cv2.resize(img, None, fx=4, fy=4, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.title(\"analyze by tesseract\", fontsize=20)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "<a id='Results'></a>\n",
    "\n",
    "In order to make easy the evaluation of the proccess a interactive function has been define:\n",
    "* The first cell allows you to run the process over one selected image from the path list and choose if you want to see all the proccess steps images\n",
    "* The seconde cell run the process over all the data an gives the overall results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395284f031f64cf9b618fd7d8b3c6ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='path', options=('screenshot_images/1+CAguilarA.png', 'screenshot_i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def main(path=images, show_all=[True, False]):\n",
    "\n",
    "    out = cv2.imread(path)\n",
    "    img = cv2.cvtColor(out, cv2.COLOR_BGR2GRAY)\n",
    "    img = 255 - img\n",
    "    \n",
    "    img = resize_document(img)\n",
    "    out = resize_document(out)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.title(\"out\", fontsize=20)\n",
    "    plt.imshow(out, cmap=\"gray\")\n",
    "    plt.show\n",
    "\n",
    "    barcode_contour = barcode_detection(img, out, show_all)\n",
    "    if len(barcode_contour):\n",
    "        flip = barcode_rotation(img, out, barcode_contour, show_all)\n",
    "        result = crop_numbers(img, out, barcode_contour, flip, show_all)\n",
    "        tesseract(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d4c9ac2a8b46f9af4366386a7c1a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('pymu_images/', 'pdf2image_images/', 'screensho…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def test_dataset(dataset=datasets,show_all=[False,True],front_pages=[False,True],back_pages=[False,True]):\n",
    "    \n",
    "    images = (glob.glob(PATH + \"*.png\") + glob.glob(PATH + \"*.jpg\") + glob.glob(PATH + \"*.jpeg\"))\n",
    "    images.sort()\n",
    "    if not front_pages:\n",
    "        images = [image for image in images if '1' in image]\n",
    "        \n",
    "    if not back_pages:\n",
    "        images = [image for image in images if '0' in image]\n",
    "\n",
    "    \n",
    "    for image in images:\n",
    "        main(image, show_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
